1. The original video. https://youtu.be/flXrLGPY3SU (Nice insights starting 2:12:30)
2. The original blog. https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/
3. Nice insights:
	1. GPT learned a lot of the structure of human language. Used parenthesis completion as example
	2. Comparison between deep computation (physical/math world and its mathematical representation) vs shallow computation (GPT). 
	3. Similarly, Aristotle's term logic which largely depends on the syntax and pattern (A=B, A=C, therefore B=C) can be learnt by GPT; but the formal logic is beyond its capability.